1.GL实现多线程 每个线程有一个状态机 要管理他们的资源共享和竞争 VK使用CmdBuffer提交到队列的方式来实现多线程  
2.VK自己管理内存  
3.VK的ComderBuffer是可以重复使用的 如果两帧一样 就直接复用 GL就还需要重新设置一次状态
      

瓷块架构: 其目的是为了减少从GPU到内存的数据量，以降低功耗。  
这些移动厂商提出一个功能就是renderpass，它允许一个应用程序向驱动程序传递一个帧画面当中的高级架构信息，移动GPU驱动程序可以利用这个信息来决定将数据带入和带出GPU的时机，来决定何时刷新内存，或者何时丢弃缓冲内容，甚至是针对图像读取等内部操作来重新划分内存。

![Exported image](Exported%20image%2020260112170215-0.png)

寄存器（Registers）：每个线程一个  
共享内存（Shared Memory）：一个块中的所有线程共同使用
 
显存（GlobalMemory）：全局内存 速度最慢 所有线程可见  
本地内存（Local Memory）：位于芯片外部 每个线程一个 当寄存器满了的时候 放在这里 慢一点  
常量内存（Constant Memory）：位于芯片外部 GPU只读 一般是CPU来设置这块 64k字节 每个线程束串行访问 但是如果多个线程束同时访问同一块内存 可以一次读取 所以比显存更快

![Exported image](Exported%20image%2020260112170217-1.png)  

![Exported image](Exported%20image%2020260112170219-2.png) ![Exported image](Exported%20image%2020260112170221-3.png) ![Exported image](Exported%20image%2020260112170223-4.png) ![Exported image](Exported%20image%2020260112170229-5.png) ![Exported image](Exported%20image%2020260112170231-6.png) ![Exported image](Exported%20image%2020260112170233-7.png) ![Exported image](Exported%20image%2020260112170236-8.png)

每个分支都会执行A1 再执行A2 然后抛弃一个结果 （但是现在的GPU都是SIMT了所以没事）

![Exported image](Exported%20image%2020260112170237-9.png)

GDDR吞吐量大 但是得数据成团了才能读取出来 所以延迟较高300ns

![Exported image](Exported%20image%2020260112170239-10.jpeg)  

因为需求有累加这种需求  
所以需要把累加变为多线程操作 所以衍生了需求是 sp之间需要数据通路  
但是10000个sp之间都要有通路的话设计成本太高  
所以衍生出了SM（流处理器） 96k字节的内存是所有4x32个线程共享的
   

实际上L1 CACHE拥有两个功能，一个是用于SM上Core之间相互共享内存，另一个则是普通的cache功能。  
1.当Core需要协同工作，并且彼此交换结果的时候，编译器编译后的指令会将部分结果储存在共享内存中，以便于不同的core获取到对应数据。
 
2.当用做普通cache功能的时候，当core需要访问GMEM数据的时候，首先会在L1中查找，如果没找到，则回去L2 cache中寻找，如果L2 cache也没有，则会从GMEM中获取数据，L1访问最快 L2 以及GMEM递减。  
缓存中的数据将会持续存在，除非出现新的数据做替换。从这个角度来看，如果Core需要从GMEM中多次访问数据，那么编程者应该将这块数据放入功能内存中，以加快他们的获取速度。
   

[https://zhuanlan.zhihu.com/p/678001378](https://zhuanlan.zhihu.com/p/678001378)

![Exported image](Exported%20image%2020260112170248-11.png)